
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split

# Split the dataframe
def get_data_splits(dataframe, valid_fraction=0.1):
    """Splits a dataframe into train, validation, and test sets.

    First, orders by the column 'click_time'. Set the size of the
    validation and test sets with the valid_fraction keyword argument.
    """

    dataframe = dataframe.sort_values('click_time')
    valid_rows = int(len(dataframe) * valid_fraction)
    train = dataframe[:-valid_rows * 2]
    # valid size == test size, last two sections of the data
    valid = dataframe[-valid_rows * 2:-valid_rows]
    test = dataframe[-valid_rows:]

    return train, valid, test

##################################
#           COLUMNS BY TYPE      #
##################################

# Categorical features
cat_features = ['director_id', 'company_id',\
                'role_name','gender','nationality', \
                'role_id', 'sic']


# Drop columns
drop_cols = ['director_name', 'company_name',\
            'end_date', 'current_role', 'role_duration',\
            'gvkey','tic'
            ]

# Date features
date_features = ['start_date', 'date',  'date_of_birth'
                ]

# Timedelta features:
timedelta_features = ['company_roles_tenure','company_roles_tenure_avg','past_role_duration',\
                    'past_roles_tenure','past_roles_tenure_avg','previous_ceo_tenure',\
                    'role_tenure','tenure_at_ceo_start'
                    ]
# Numerical features
num_features = ['network_size','past_roles_count','age', \
                'company_roles_count','active_roles_count','active_roles_count_max',\
                'firm_rtn_1m', 'firm_rtn_3m', 'firm_rtn_6m',\
                'firm_rtn_12m', 'firm_rtn_24m', 'firm_rtn_36m',\
                'index_rtn_1m', 'index_rtn_3m', 'index_rtn_6m',\
                'index_rtn_12m', 'index_rtn_24m', 'index_rtn_36m',\
                'sector_rtn_1m', 'sector_rtn_3m', 'sector_rtn_6m',\
                'sector_rtn_12m','sector_rtn_24m', 'sector_rtn_36m'
                ]

# Boolean variables
bool_features = ['role_extension','nationality_was_missing',\
       'network_size_was_missing', 'past_roles_tenure_avg_was_missing',\
       'company_roles_tenure_avg_was_missing','ceo','chair', 'chair_ceo',\
       'previous_ceo_tenure_was_missing', 'firm_rtn_1m_was_missing',\
       'firm_rtn_3m_was_missing', 'firm_rtn_6m_was_missing',\
       'firm_rtn_12m_was_missing', 'firm_rtn_24m_was_missing',\
       'firm_rtn_36m_was_missing', 'sic_was_missing',\
       'sector_rtn_1m_was_missing', 'sector_rtn_3m_was_missing',\
       'sector_rtn_6m_was_missing', 'sector_rtn_12m_was_missing',\
       'sector_rtn_24m_was_missing', 'sector_rtn_36m_was_missing'
]


# Target variable
y_var = ['turnover']

# X_full.drop(drop_cols, axis=1, inplace=True)
# Check column types
def check_column_types(df, cols, type):
    dict = {}
    df_ceos[cname].dtypes
    return dict

types = ['int64', 'float64']
import pprint as pp
import pandas.api.types as ptypes

# Assert all data types

assert all(ptypes.is_object_dtype(df_ceos[col]) for col in cat_features)
assert all(ptypes.is_timedelta64_dtype(df_ceos[col]) for col in timedelta_features)
assert all(ptypes.is_datetime64_dtype(df_ceos[col]) for col in date_features)
assert all((ptypes.is_int64_dtype(df_ceos[col])|ptypes.is_float_dtype(df_ceos[col])) for col in num_features)
